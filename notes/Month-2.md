# M2-W5-D1

## Phase: Month 2 - LLM API å·¥ç¨‹åŒ– | Week 5 - LLMClient åŸºç¡€å°è£…

**ä»Šæ—¥æ ¸å¿ƒç›®æ ‡**ï¼šè®¾è®¡å¯æ›¿æ¢çš„ LLM è°ƒç”¨å±‚éª¨æ¶ï¼ˆæ¥å£ + æ•°æ®ç»“æ„ + Provider æŠ½è±¡ï¼‰

------

### Whyï¼šä¸å­¦ä¼šå¯¼è‡´çš„å·¥ç¨‹æ­»ç©´

ç›´æ¥åœ¨ä¸šåŠ¡ä»£ç é‡Œå†™ `openai.ChatCompletion.create(...)` ä¼šæ€æ ·ï¼Ÿ

- æ¢æ¨¡å‹ä¾›åº”å•†ï¼ˆOpenAI â†’ DeepSeek â†’ æœ¬åœ° Ollamaï¼‰è¦**æ”¹æ‰€æœ‰è°ƒç”¨ç‚¹**
- æµ‹è¯•æ—¶å¿…é¡»çœŸå®è°ƒ APIï¼Œæ¯è·‘ä¸€æ¬¡æµ‹è¯•å°±çƒ§é’±
- è¾“å…¥è¾“å‡ºæ ¼å¼æ•£è½å„å¤„ï¼Œæ²¡æœ‰ç»Ÿä¸€çš„æ•°æ®ç»“æ„ï¼Œåç»­åŠ æ—¥å¿—/é‡è¯•/ç¼“å­˜æ— å¤„ä¸‹æ‰‹

Java åç«¯ç»éªŒå¯¹ç…§ï¼šä½ é¡¹ç›®é‡Œå°è£…äº† HttpGetClient/HttpPostClientï¼ŒService æ³¨å…¥ Client è€Œä¸æ˜¯ç›´æ¥ newâ€”â€”LLMClient + Provider æ˜¯å®Œå…¨ç›¸åŒçš„æ€è·¯ã€‚

------

### Whatï¼šç¬¬ä¸€æ€§åŸç†

**æ ¸å¿ƒå…¬å¼**ï¼š

> LLMClientï¼ˆè°ƒç”¨å…¥å£ï¼‰= Provider æŠ½è±¡ï¼ˆè°æ¥åšï¼‰+ æ•°æ®ç»“æ„ï¼ˆè¾“å…¥è¾“å‡ºé•¿ä»€ä¹ˆæ ·ï¼‰

ä¸‰ä¸ªè§’è‰²çš„å…³ç³»ï¼š

- **ChatRequest / ChatResponse**ï¼šå®šä¹‰"æ•°æ®é•¿ä»€ä¹ˆæ ·"
- **LLMProviderï¼ˆProtocolï¼‰**ï¼šå®šä¹‰"èƒ½åšä»€ä¹ˆ"â€”â€”æœ‰ chat æ–¹æ³•å°±è¡Œ
- **LLMClient**ï¼šå®šä¹‰"æ€ä¹ˆç”¨"â€”â€”æŒæœ‰ Provider å¼•ç”¨ï¼Œè°ƒç”¨ chat

ç±»æ¯”ï¼šé¤å…æ¨¡å‹

- ChatRequest = ç‚¹èœå•ï¼ˆèœåã€å£å‘³è¦æ±‚ï¼‰
- ChatResponse = ä¸Šçš„èœï¼ˆèœæœ¬èº« + å°ç¥¨ä»·æ ¼ï¼‰
- LLMProvider = å¨å¸ˆæ¥å£ï¼ˆèƒ½åšèœå°±è¡Œï¼Œä¸ç®¡æ˜¯ä¸­é¤å¨å¸ˆè¿˜æ˜¯è¥¿é¤å¨å¸ˆï¼‰
- LLMClient = æœåŠ¡å‘˜ï¼ˆæ¥å• â†’ é€’ç»™å¨å¸ˆ â†’ æŠŠèœç«¯å›æ¥ï¼‰

------

### Howï¼šæœ€å°å¯è¿è¡ŒèŒƒå¼

**é¡¹ç›®ç»“æ„ï¼š**

```
llm-client/
  src/llm_client/
    models.py          â† æ•°æ®ç»“æ„
    provider.py         â† æŠ½è±¡æ¥å£
    mock_provider.py    â† æµ‹è¯•ç”¨å®ç°
    client.py           â† è°ƒç”¨å…¥å£
  demo.py               â† ä¸²è”éªŒè¯
```

**models.py â€” æ•°æ®ç»“æ„ï¼š**

```python
@dataclass
class ChatRequest:
    messages: list[dict[str, str]]   # [{"role": "user", "content": "..."}]
    model: str = "gpt-3.5-turbo"

@dataclass
class ChatResponse:
    content: str
    input_tokens: int      # è¾“å…¥ tokenï¼ˆè®¡è´¹ç”¨ï¼‰
    output_tokens: int     # è¾“å‡º tokenï¼ˆå•ä»·ä¸åŒï¼Œå¿…é¡»åˆ†å¼€è®°ï¼‰
```

**provider.py â€” æŠ½è±¡æ¥å£ï¼š**

```python
class LLMProvider(Protocol):
    def chat(self, request: ChatRequest) -> ChatResponse: ...
```

**client.py â€” è°ƒç”¨å…¥å£ï¼ˆç»„åˆæ¨¡å¼ï¼‰ï¼š**

```python
class LLMClient:
    def __init__(self, provider: LLMProvider):
        self.provider = provider

    def chat(self, request: ChatRequest) -> ChatResponse:
        return self.provider.chat(request)
```

**ä½¿ç”¨æ–¹å¼ï¼š**

```python
client = LLMClient(MockProvider())       # æµ‹è¯•ç¯å¢ƒ
client = LLMClient(DeepSeekProvider())   # ç”Ÿäº§ç¯å¢ƒ
# LLMClient ä»£ç é›¶ä¿®æ”¹
```

------

### Pitfallï¼šçœŸå®è¸©å‘

- **token åªè®°ä¸€ä¸ªæ€»æ•°**ï¼šè¾“å…¥å’Œè¾“å‡ºå•ä»·ä¸åŒï¼ˆGPT-4 è¾“å‡ºå•ä»·æ˜¯è¾“å…¥çš„ 3 å€ï¼‰ï¼Œä¸åˆ†å¼€è®°å°±ç®—ä¸æ¸…æˆæœ¬
- **messages ç±»å‹å†™ list ä¸åŠ æ³›å‹**ï¼šåˆ«äººçœ‹ä¸å‡ºé‡Œé¢æ˜¯ä»€ä¹ˆç»“æ„ï¼Œåç»­ç»´æŠ¤æˆæœ¬é«˜
- **è¿‡æ—©åˆ†ç›®å½•**ï¼š3 ä¸ªæ–‡ä»¶å°±åˆ† models/ å’Œ client/ ä¸¤ä¸ªå­ç›®å½•ï¼Œå¯¼è‡´ import è·¯å¾„å˜æ·±ã€å®¹æ˜“å‡ºé”™ã€‚æ–‡ä»¶å°‘äº 10 ä¸ªæ—¶ä¿æŒæ‰å¹³
- **demo.py ç”¨ç›¸å¯¹å¯¼å…¥**ï¼šé¡¹ç›®æ ¹ç›®å½•çš„è„šæœ¬ä¸åœ¨åŒ…å†…ï¼Œä¸èƒ½ç”¨ `from .xxx`ï¼Œè¦ç”¨åŒ…åç›´æ¥å¯¼å…¥

------

### Applicationï¼šåœ¨ RAG/Agent/æ¶æ„ä¸­çš„ä½ç½®

æœ¬å‘¨ï¼ˆW5ï¼‰å…¨è²Œï¼šD1 æ¥å£è®¾è®¡ï¼ˆä»Šå¤©ï¼Œéª¨æ¶ï¼‰â†’ D2 è¶…æ—¶+é‡è¯• â†’ D3 ç»“æ„åŒ–è¾“å‡º â†’ D4 Mock æµ‹è¯• â†’ D5 README+æˆæœ¬ä¼°ç®—

åç»­å¤ç”¨ï¼šW6 Tools è°ƒç”¨ LLMClient â†’ W8 FastAPI åŒ…è£… LLMClient â†’ M3 RAG æ£€ç´¢ç»“æœæ³¨å…¥ messages â†’ M5 Agent å¤šè½®è°ƒç”¨+å·¥å…·

------

### è§†è§‰é—­ç¯

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ä¸šåŠ¡ä»£ç      â”‚  demo.py / Service / Agent
â”‚  (è°ƒç”¨æ–¹)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ ä¾èµ–
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLMClient   â”‚  æŒæœ‰ Providerï¼Œè½¬å‘ chat()
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ ç»„åˆï¼ˆä¸æ˜¯ç»§æ‰¿ï¼‰
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLMProvider  â”‚â—„â”€â”€â”€â”€â”‚ Protocol æ¥å£     â”‚
â”‚ (æŠ½è±¡)       â”‚     â”‚ chat(req) -> res â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ å®ç°ï¼ˆé¸­å­ç±»å‹ï¼‰
       â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚MockProv  â”‚DeepSeek  â”‚OpenAI    â”‚  â† æ–°å¢ä¸æ”¹ Client
  â”‚(æµ‹è¯•)    â”‚Prov      â”‚Prov      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ•°æ®æµï¼š
ChatRequest â”€â”€â†’ Provider.chat() â”€â”€â†’ ChatResponse
(messages,      (å„å®¶APIå®ç°)        (content,
 model)                              input_tokens,
                                     output_tokens)
```

------

### å·¥ç¨‹å¸ˆè®°å¿†åˆ†å±‚

- ğŸ—‘ï¸ **åƒåœ¾åŒºï¼ˆæŸ¥æ–‡æ¡£ï¼‰**ï¼šdataclass è£…é¥°å™¨è¯­æ³•ã€Protocol çš„ import è·¯å¾„ã€PyCharm çš„ Sources Root é…ç½®
- ğŸ” **ç´¢å¼•åŒºï¼ˆè®°å…³é”®è¯ï¼‰**ï¼šmessages ç»“æ„æ˜¯ role + contentã€token åˆ† input/outputã€src å¸ƒå±€åŒ…å†…ç›¸å¯¹å¯¼å…¥ `from .xxx`
- ğŸ’ **æ ¸å¿ƒåŒºï¼ˆå¿…é¡»å†…åŒ–ï¼‰**ï¼šProvider æŠ½è±¡çš„ç›®çš„æ˜¯æ–°å¢å®ç°ä¸æ”¹è°ƒç”¨æ–¹ã€LLMClient ç»„åˆæ¨¡å¼ `__init__` æ¥æ”¶æ¥å£ã€é¸­å­ç±»å‹ä¸éœ€è¦ç»§æ‰¿åªéœ€æ–¹æ³•ç­¾åä¸€è‡´ã€æ–‡ä»¶å°‘æ—¶ä¿æŒæ‰å¹³åˆ«è¿‡æ—©åˆ†ç›®å½•

---

# M2-W5-D2

## Phase

Month 2 Â· LLM API å·¥ç¨‹åŒ– Â· Week 5 LLMClient åŸºç¡€å°è£… Â· Day 2 è¶…æ—¶æ§åˆ¶ + æŒ‡æ•°é€€é¿é‡è¯•

## ä»Šæ—¥æ ¸å¿ƒç›®æ ‡

ä¸º LLMClient åŠ ä¸Š"é˜²å¾¡å±‚"â€”â€”é”™è¯¯åˆ†ç±» + æŒ‡æ•°é€€é¿é‡è¯•ï¼Œè®© API è°ƒç”¨åœ¨ç½‘ç»œæŠ–åŠ¨å’ŒæœåŠ¡ç«¯æ•…éšœä¸‹ä¸ä¼šä¸€ç¢°å°±æ­»ã€‚

------

## Whyï¼šä¸å­¦ä¼šå¯¼è‡´çš„å·¥ç¨‹æ­»ç©´

LLM API è°ƒç”¨æœ¬è´¨æ˜¯è¿œç¨‹ç½‘ç»œè¯·æ±‚ï¼Œ100% ä¼šé‡åˆ°è¶…æ—¶ã€é™æµã€æœåŠ¡ç«¯æ•…éšœã€‚æ²¡æœ‰é‡è¯•æœºåˆ¶çš„ LLMClientï¼š

- ä¸€æ¬¡ç½‘ç»œæŠ–åŠ¨å°±æ•´ä¸ªåŠŸèƒ½ä¸å¯ç”¨
- 429 é™æµåç–¯ç‹‚é‡è¯• â†’ é‡è¯•é£æš´ï¼ˆRetry Stormï¼‰ â†’ æœåŠ¡ç«¯æ›´åŠ è¿‡è½½
- 401/422 è¿™ç§æ°¸ä¹…é”™è¯¯ä¹Ÿåœ¨å‚»å‚»é‡è¯• â†’ æµªè´¹æ—¶é—´ã€æµªè´¹é’±

ç”Ÿäº§ç¯å¢ƒæ²¡æœ‰é‡è¯• = è£¸å¥”ã€‚

------

## Whatï¼šç¬¬ä¸€æ€§åŸç† + ç±»æ¯”

### é”™è¯¯åˆ†ç±»ï¼šTransient vs Permanent

æ ¸å¿ƒåˆ¤æ–­æ ‡å‡†ï¼š**è¿™ä¸ªé”™è¯¯æ˜¯"æš‚æ—¶çš„"è¿˜æ˜¯"æ°¸ä¹…çš„"ï¼Ÿ**

- **Transientï¼ˆæš‚æ—¶æ€§ï¼‰**ï¼šè¶…æ—¶ã€429ã€500 â†’ ä¸‹æ¬¡å¯èƒ½å¥½ â†’ å€¼å¾—é‡è¯•
- **Permanentï¼ˆæ°¸ä¹…æ€§ï¼‰**ï¼š401ã€422 â†’ é‡è¯•ä¸€ä¸‡æ¬¡ä¹Ÿæ²¡ç”¨ â†’ ç›´æ¥æŠ›å‡º

ç±»æ¯”ï¼šæ‰“ç”µè¯æ²¡æ¥ï¼ˆæš‚æ—¶çš„ï¼Œè¿‡ä¼šå„¿å†æ‰“ï¼‰ï¼Œå·ç æ˜¯ç©ºå·ï¼ˆæ°¸ä¹…çš„ï¼Œæ‰“å¤šå°‘æ¬¡éƒ½æ²¡ç”¨ï¼‰ã€‚

### æŒ‡æ•°é€€é¿ï¼ˆExponential Backoffï¼‰

é—®é¢˜ï¼šé‡è¯•ç­‰å¤šä¹…ï¼Ÿå›ºå®šç­‰ 1 ç§’ â†’ æ‰€æœ‰å®¢æˆ·ç«¯åŒæ—¶é‡è¯• â†’ é‡è¯•é£æš´ã€‚

è§£æ³•ï¼šæ¯æ¬¡é‡è¯•ï¼Œç­‰å¾…æ—¶é—´ç¿»å€ã€‚

å…¬å¼ï¼š`delay = min(base_delay Ã— 2^attempt, max_delay)`

- attempt 0 â†’ 1s
- attempt 1 â†’ 2s
- attempt 2 â†’ 4s
- attempt 3 â†’ 8s

max_delay æ˜¯å®‰å…¨é˜€ï¼Œé˜²æ­¢ç­‰å¾…æ—¶é—´æŒ‡æ•°çˆ†ç‚¸ã€‚

è¿›é˜¶ï¼šJitterï¼ˆéšæœºæŠ–åŠ¨ï¼‰åœ¨ç­‰å¾…æ—¶é—´ä¸ŠåŠ éšæœºåç§»ï¼Œè¿›ä¸€æ­¥æ‰“æ•£é‡è¯•æ—¶æœºã€‚

------

## Howï¼šæœ€å°å¯è¿è¡ŒèŒƒå¼

### æ ¸å¿ƒç»„ä»¶ï¼šRetryHandler

```python
class RetryHandler:
    def __init__(self, max_retries=3, base_delay=1, max_delay=10, retryable_errors=()):
        self.max_retries = max_retries
        self.base_delay = base_delay
        self.max_delay = max_delay
        self.retryable_errors = retryable_errors

    def is_retryable_error(self, error) -> bool:
        return isinstance(error, self.retryable_errors)

    def execute(self, operation, *args, **kwargs):
        retry_count = 0  # å±€éƒ¨å˜é‡ï¼Œä¸æ˜¯å®ä¾‹å±æ€§ï¼
        while True:
            try:
                return operation(*args, **kwargs)
            except Exception as e:
                if not self.is_retryable_error(e):
                    raise
                if retry_count >= self.max_retries:
                    raise
                retry_count += 1
                delay = min(self.base_delay * 2 ** (retry_count - 1), self.max_delay)
                time.sleep(delay)
```

### ç»„åˆè¿› LLMClient

```python
class LLMClient:
    def __init__(self, provider: LLMProvider, retry_handler: RetryHandler):
        self.provider = provider
        self.retry_handler = retry_handler

    def chat(self, request: ChatRequest) -> ChatResponse:
        return self.retry_handler.execute(self.provider.chat, request)
```

### å¼‚å¸¸ä½“ç³»

```python
class LLMError(Exception): pass          # åŸºç±»ï¼Œå¿…é¡»ç»§æ‰¿ Exception
class LLMTimeoutError(LLMError): pass    # å¯é‡è¯•
class LLMRateLimitError(LLMError): pass  # å¯é‡è¯•
class LLMServerError(LLMError): pass     # å¯é‡è¯•
class LLMAuthError(LLMError): pass       # ä¸å¯é‡è¯•
class LLMRequestError(LLMError): pass    # ä¸å¯é‡è¯•
```

### ç»„è£…

```python
retry_handler = RetryHandler(
    retryable_errors=(LLMTimeoutError, LLMRateLimitError, LLMServerError)
)
client = LLMClient(provider=provider, retry_handler=retry_handler)
```

------

## Pitfallï¼šçœŸå®è¸©å‘

- **retry_count æ”¾æˆå®ä¾‹å±æ€§**ï¼šç¬¬ä¸€æ¬¡è°ƒç”¨é‡è¯• 2 æ¬¡åï¼Œç¬¬äºŒæ¬¡è°ƒç”¨åªå‰© 1 æ¬¡é‡è¯•é¢åº¦ã€‚å¿…é¡»æ˜¯ execute() å†…çš„å±€éƒ¨å˜é‡ï¼Œæ¯æ¬¡è°ƒç”¨äº’ç›¸ç‹¬ç«‹
- **LLMError å¿˜è®°ç»§æ‰¿ Exception**ï¼šPython ä¸å…è®¸ raise ä¸€ä¸ªéå¼‚å¸¸å¯¹è±¡ï¼Œ`raise LLMTimeoutError()` ä¼šç›´æ¥æŠ¥ TypeError
- **retryable_errors é»˜è®¤ç©º tuple**ï¼šä¸ä¼  = ä»€ä¹ˆéƒ½ä¸é‡è¯•ã€‚`isinstance(error, ())` æ°¸è¿œ False
- **ChatResponse ç¼ºå­—æ®µ**ï¼šFailingMockProvider æˆåŠŸè¿”å›æ—¶å¿˜äº†ä¼  input_tokens/output_tokensï¼Œdataclass ä¼šæŠ¥ missing arguments

------

## Applicationï¼šåœ¨ RAG / Agent / æ¶æ„ä¸­çš„ä½ç½®

- **RAG**ï¼šæ£€ç´¢æ—¶è°ƒ Embedding API + ç”Ÿæˆæ—¶è°ƒ LLM APIï¼Œä»»ä½•ä¸€æ­¥éƒ½éœ€è¦é‡è¯•
- **Agent**ï¼šå·¥å…·è°ƒç”¨å¤±è´¥ã€LLM è§„åˆ’å¤±è´¥ï¼Œéƒ½èµ° RetryHandler çš„é‡è¯•é€»è¾‘
- **ç”Ÿäº§æœåŠ¡**ï¼šMonth 6 ä¼šåŠ æ›´å®Œæ•´çš„è§‚æµ‹ï¼ˆé‡è¯•æ¬¡æ•°æŒ‡æ ‡ã€å¤±è´¥ç‡å‘Šè­¦ï¼‰ï¼ŒRetryHandler æ˜¯è§‚æµ‹æ•°æ®çš„æ¥æº

------

## è§†è§‰é—­ç¯

```
chat(request)
    â”‚
    â–¼
RetryHandler.execute()
    â”‚
    â”œâ”€ try: provider.chat(request) â”€â”€â†’ æˆåŠŸ â†’ è¿”å› ChatResponse
    â”‚
    â””â”€ except:
        â”‚
        â”œâ”€ is_retryable? â”€â”€Noâ”€â”€â†’ ç›´æ¥ raiseï¼ˆ401/422ï¼‰
        â”‚
        â””â”€ Yes
            â”‚
            â”œâ”€ è¶…è¿‡ max_retries? â”€â”€Yesâ”€â”€â†’ raise
            â”‚
            â””â”€ No â†’ sleep(delay) â†’ å›åˆ° try
                     delay = min(base Ã— 2^attempt, max)

ç»„åˆå…³ç³»ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLMClient                      â”‚
â”‚  â”œâ”€â”€ provider: LLMProvider     â”‚  â† D1
â”‚  â””â”€â”€ retry_handler: RetryHandlerâ”‚ â† D2
â”‚       â”œâ”€â”€ retryable_errors     â”‚
â”‚       â””â”€â”€ execute() åŒ…è£¹è°ƒç”¨    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

------

## å·¥ç¨‹å¸ˆè®°å¿†åˆ†å±‚

- ğŸ—‘ï¸ åƒåœ¾åŒºï¼ˆæŸ¥æ–‡æ¡£ï¼‰ï¼štime.sleep() çš„ç²¾ç¡®ç”¨æ³•ã€isinstance æ”¯æŒ tuple çš„è¯­æ³•ç»†èŠ‚
- ğŸ” ç´¢å¼•åŒºï¼ˆè®°å…³é”®è¯ï¼‰ï¼šJitter éšæœºæŠ–åŠ¨ã€Retry Storm é‡è¯•é£æš´ã€min() å°é¡¶
- ğŸ’ æ ¸å¿ƒåŒºï¼ˆå¿…é¡»å†…åŒ–ï¼‰ï¼šTransient vs Permanent é”™è¯¯åˆ†ç±»å†³å®šé‡è¯•ç­–ç•¥ï¼›æŒ‡æ•°é€€é¿å…¬å¼ `min(base Ã— 2^attempt, max)`ï¼›RetryHandler ç‹¬ç«‹äº LLMClientï¼Œé€šè¿‡ç»„åˆæ³¨å…¥ï¼›retry_count å¿…é¡»æ˜¯å±€éƒ¨å˜é‡ä¸æ˜¯å®ä¾‹å±æ€§

---

