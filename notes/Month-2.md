# M2-W5-D1

## Phase: Month 2 - LLM API å·¥ç¨‹åŒ– | Week 5 - LLMClient åŸºç¡€å°è£…

**ä»Šæ—¥æ ¸å¿ƒç›®æ ‡**ï¼šè®¾è®¡å¯æ›¿æ¢çš„ LLM è°ƒç”¨å±‚éª¨æ¶ï¼ˆæ¥å£ + æ•°æ®ç»“æ„ + Provider æŠ½è±¡ï¼‰

------

### Whyï¼šä¸å­¦ä¼šå¯¼è‡´çš„å·¥ç¨‹æ­»ç©´

ç›´æ¥åœ¨ä¸šåŠ¡ä»£ç é‡Œå†™ `openai.ChatCompletion.create(...)` ä¼šæ€æ ·ï¼Ÿ

- æ¢æ¨¡å‹ä¾›åº”å•†ï¼ˆOpenAI â†’ DeepSeek â†’ æœ¬åœ° Ollamaï¼‰è¦**æ”¹æ‰€æœ‰è°ƒç”¨ç‚¹**
- æµ‹è¯•æ—¶å¿…é¡»çœŸå®è°ƒ APIï¼Œæ¯è·‘ä¸€æ¬¡æµ‹è¯•å°±çƒ§é’±
- è¾“å…¥è¾“å‡ºæ ¼å¼æ•£è½å„å¤„ï¼Œæ²¡æœ‰ç»Ÿä¸€çš„æ•°æ®ç»“æ„ï¼Œåç»­åŠ æ—¥å¿—/é‡è¯•/ç¼“å­˜æ— å¤„ä¸‹æ‰‹

Java åç«¯ç»éªŒå¯¹ç…§ï¼šä½ é¡¹ç›®é‡Œå°è£…äº† HttpGetClient/HttpPostClientï¼ŒService æ³¨å…¥ Client è€Œä¸æ˜¯ç›´æ¥ newâ€”â€”LLMClient + Provider æ˜¯å®Œå…¨ç›¸åŒçš„æ€è·¯ã€‚

------

### Whatï¼šç¬¬ä¸€æ€§åŸç†

**æ ¸å¿ƒå…¬å¼**ï¼š

> LLMClientï¼ˆè°ƒç”¨å…¥å£ï¼‰= Provider æŠ½è±¡ï¼ˆè°æ¥åšï¼‰+ æ•°æ®ç»“æ„ï¼ˆè¾“å…¥è¾“å‡ºé•¿ä»€ä¹ˆæ ·ï¼‰

ä¸‰ä¸ªè§’è‰²çš„å…³ç³»ï¼š

- **ChatRequest / ChatResponse**ï¼šå®šä¹‰"æ•°æ®é•¿ä»€ä¹ˆæ ·"
- **LLMProviderï¼ˆProtocolï¼‰**ï¼šå®šä¹‰"èƒ½åšä»€ä¹ˆ"â€”â€”æœ‰ chat æ–¹æ³•å°±è¡Œ
- **LLMClient**ï¼šå®šä¹‰"æ€ä¹ˆç”¨"â€”â€”æŒæœ‰ Provider å¼•ç”¨ï¼Œè°ƒç”¨ chat

ç±»æ¯”ï¼šé¤å…æ¨¡å‹

- ChatRequest = ç‚¹èœå•ï¼ˆèœåã€å£å‘³è¦æ±‚ï¼‰
- ChatResponse = ä¸Šçš„èœï¼ˆèœæœ¬èº« + å°ç¥¨ä»·æ ¼ï¼‰
- LLMProvider = å¨å¸ˆæ¥å£ï¼ˆèƒ½åšèœå°±è¡Œï¼Œä¸ç®¡æ˜¯ä¸­é¤å¨å¸ˆè¿˜æ˜¯è¥¿é¤å¨å¸ˆï¼‰
- LLMClient = æœåŠ¡å‘˜ï¼ˆæ¥å• â†’ é€’ç»™å¨å¸ˆ â†’ æŠŠèœç«¯å›æ¥ï¼‰

------

### Howï¼šæœ€å°å¯è¿è¡ŒèŒƒå¼

**é¡¹ç›®ç»“æ„ï¼š**

```
llm-client/
  src/llm_client/
    models.py          â† æ•°æ®ç»“æ„
    provider.py         â† æŠ½è±¡æ¥å£
    mock_provider.py    â† æµ‹è¯•ç”¨å®ç°
    client.py           â† è°ƒç”¨å…¥å£
  demo.py               â† ä¸²è”éªŒè¯
```

**models.py â€” æ•°æ®ç»“æ„ï¼š**

```python
@dataclass
class ChatRequest:
    messages: list[dict[str, str]]   # [{"role": "user", "content": "..."}]
    model: str = "gpt-3.5-turbo"

@dataclass
class ChatResponse:
    content: str
    input_tokens: int      # è¾“å…¥ tokenï¼ˆè®¡è´¹ç”¨ï¼‰
    output_tokens: int     # è¾“å‡º tokenï¼ˆå•ä»·ä¸åŒï¼Œå¿…é¡»åˆ†å¼€è®°ï¼‰
```

**provider.py â€” æŠ½è±¡æ¥å£ï¼š**

```python
class LLMProvider(Protocol):
    def chat(self, request: ChatRequest) -> ChatResponse: ...
```

**client.py â€” è°ƒç”¨å…¥å£ï¼ˆç»„åˆæ¨¡å¼ï¼‰ï¼š**

```python
class LLMClient:
    def __init__(self, provider: LLMProvider):
        self.provider = provider

    def chat(self, request: ChatRequest) -> ChatResponse:
        return self.provider.chat(request)
```

**ä½¿ç”¨æ–¹å¼ï¼š**

```python
client = LLMClient(MockProvider())       # æµ‹è¯•ç¯å¢ƒ
client = LLMClient(DeepSeekProvider())   # ç”Ÿäº§ç¯å¢ƒ
# LLMClient ä»£ç é›¶ä¿®æ”¹
```

------

### Pitfallï¼šçœŸå®è¸©å‘

- **token åªè®°ä¸€ä¸ªæ€»æ•°**ï¼šè¾“å…¥å’Œè¾“å‡ºå•ä»·ä¸åŒï¼ˆGPT-4 è¾“å‡ºå•ä»·æ˜¯è¾“å…¥çš„ 3 å€ï¼‰ï¼Œä¸åˆ†å¼€è®°å°±ç®—ä¸æ¸…æˆæœ¬
- **messages ç±»å‹å†™ list ä¸åŠ æ³›å‹**ï¼šåˆ«äººçœ‹ä¸å‡ºé‡Œé¢æ˜¯ä»€ä¹ˆç»“æ„ï¼Œåç»­ç»´æŠ¤æˆæœ¬é«˜
- **è¿‡æ—©åˆ†ç›®å½•**ï¼š3 ä¸ªæ–‡ä»¶å°±åˆ† models/ å’Œ client/ ä¸¤ä¸ªå­ç›®å½•ï¼Œå¯¼è‡´ import è·¯å¾„å˜æ·±ã€å®¹æ˜“å‡ºé”™ã€‚æ–‡ä»¶å°‘äº 10 ä¸ªæ—¶ä¿æŒæ‰å¹³
- **demo.py ç”¨ç›¸å¯¹å¯¼å…¥**ï¼šé¡¹ç›®æ ¹ç›®å½•çš„è„šæœ¬ä¸åœ¨åŒ…å†…ï¼Œä¸èƒ½ç”¨ `from .xxx`ï¼Œè¦ç”¨åŒ…åç›´æ¥å¯¼å…¥

------

### Applicationï¼šåœ¨ RAG/Agent/æ¶æ„ä¸­çš„ä½ç½®

æœ¬å‘¨ï¼ˆW5ï¼‰å…¨è²Œï¼šD1 æ¥å£è®¾è®¡ï¼ˆä»Šå¤©ï¼Œéª¨æ¶ï¼‰â†’ D2 è¶…æ—¶+é‡è¯• â†’ D3 ç»“æ„åŒ–è¾“å‡º â†’ D4 Mock æµ‹è¯• â†’ D5 README+æˆæœ¬ä¼°ç®—

åç»­å¤ç”¨ï¼šW6 Tools è°ƒç”¨ LLMClient â†’ W8 FastAPI åŒ…è£… LLMClient â†’ M3 RAG æ£€ç´¢ç»“æœæ³¨å…¥ messages â†’ M5 Agent å¤šè½®è°ƒç”¨+å·¥å…·

------

### è§†è§‰é—­ç¯

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ä¸šåŠ¡ä»£ç      â”‚  demo.py / Service / Agent
â”‚  (è°ƒç”¨æ–¹)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ ä¾èµ–
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLMClient   â”‚  æŒæœ‰ Providerï¼Œè½¬å‘ chat()
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ ç»„åˆï¼ˆä¸æ˜¯ç»§æ‰¿ï¼‰
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLMProvider  â”‚â—„â”€â”€â”€â”€â”‚ Protocol æ¥å£     â”‚
â”‚ (æŠ½è±¡)       â”‚     â”‚ chat(req) -> res â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ å®ç°ï¼ˆé¸­å­ç±»å‹ï¼‰
       â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚MockProv  â”‚DeepSeek  â”‚OpenAI    â”‚  â† æ–°å¢ä¸æ”¹ Client
  â”‚(æµ‹è¯•)    â”‚Prov      â”‚Prov      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ•°æ®æµï¼š
ChatRequest â”€â”€â†’ Provider.chat() â”€â”€â†’ ChatResponse
(messages,      (å„å®¶APIå®ç°)        (content,
 model)                              input_tokens,
                                     output_tokens)
```

------

### å·¥ç¨‹å¸ˆè®°å¿†åˆ†å±‚

- ğŸ—‘ï¸ **åƒåœ¾åŒºï¼ˆæŸ¥æ–‡æ¡£ï¼‰**ï¼šdataclass è£…é¥°å™¨è¯­æ³•ã€Protocol çš„ import è·¯å¾„ã€PyCharm çš„ Sources Root é…ç½®
- ğŸ” **ç´¢å¼•åŒºï¼ˆè®°å…³é”®è¯ï¼‰**ï¼šmessages ç»“æ„æ˜¯ role + contentã€token åˆ† input/outputã€src å¸ƒå±€åŒ…å†…ç›¸å¯¹å¯¼å…¥ `from .xxx`
- ğŸ’ **æ ¸å¿ƒåŒºï¼ˆå¿…é¡»å†…åŒ–ï¼‰**ï¼šProvider æŠ½è±¡çš„ç›®çš„æ˜¯æ–°å¢å®ç°ä¸æ”¹è°ƒç”¨æ–¹ã€LLMClient ç»„åˆæ¨¡å¼ `__init__` æ¥æ”¶æ¥å£ã€é¸­å­ç±»å‹ä¸éœ€è¦ç»§æ‰¿åªéœ€æ–¹æ³•ç­¾åä¸€è‡´ã€æ–‡ä»¶å°‘æ—¶ä¿æŒæ‰å¹³åˆ«è¿‡æ—©åˆ†ç›®å½•

---

# M2-W5-D2

## Phase

Month 2 Â· LLM API å·¥ç¨‹åŒ– Â· Week 5 LLMClient åŸºç¡€å°è£… Â· Day 2 è¶…æ—¶æ§åˆ¶ + æŒ‡æ•°é€€é¿é‡è¯•

## ä»Šæ—¥æ ¸å¿ƒç›®æ ‡

ä¸º LLMClient åŠ ä¸Š"é˜²å¾¡å±‚"â€”â€”é”™è¯¯åˆ†ç±» + æŒ‡æ•°é€€é¿é‡è¯•ï¼Œè®© API è°ƒç”¨åœ¨ç½‘ç»œæŠ–åŠ¨å’ŒæœåŠ¡ç«¯æ•…éšœä¸‹ä¸ä¼šä¸€ç¢°å°±æ­»ã€‚

------

## Whyï¼šä¸å­¦ä¼šå¯¼è‡´çš„å·¥ç¨‹æ­»ç©´

LLM API è°ƒç”¨æœ¬è´¨æ˜¯è¿œç¨‹ç½‘ç»œè¯·æ±‚ï¼Œ100% ä¼šé‡åˆ°è¶…æ—¶ã€é™æµã€æœåŠ¡ç«¯æ•…éšœã€‚æ²¡æœ‰é‡è¯•æœºåˆ¶çš„ LLMClientï¼š

- ä¸€æ¬¡ç½‘ç»œæŠ–åŠ¨å°±æ•´ä¸ªåŠŸèƒ½ä¸å¯ç”¨
- 429 é™æµåç–¯ç‹‚é‡è¯• â†’ é‡è¯•é£æš´ï¼ˆRetry Stormï¼‰ â†’ æœåŠ¡ç«¯æ›´åŠ è¿‡è½½
- 401/422 è¿™ç§æ°¸ä¹…é”™è¯¯ä¹Ÿåœ¨å‚»å‚»é‡è¯• â†’ æµªè´¹æ—¶é—´ã€æµªè´¹é’±

ç”Ÿäº§ç¯å¢ƒæ²¡æœ‰é‡è¯• = è£¸å¥”ã€‚

------

## Whatï¼šç¬¬ä¸€æ€§åŸç† + ç±»æ¯”

### é”™è¯¯åˆ†ç±»ï¼šTransient vs Permanent

æ ¸å¿ƒåˆ¤æ–­æ ‡å‡†ï¼š**è¿™ä¸ªé”™è¯¯æ˜¯"æš‚æ—¶çš„"è¿˜æ˜¯"æ°¸ä¹…çš„"ï¼Ÿ**

- **Transientï¼ˆæš‚æ—¶æ€§ï¼‰**ï¼šè¶…æ—¶ã€429ã€500 â†’ ä¸‹æ¬¡å¯èƒ½å¥½ â†’ å€¼å¾—é‡è¯•
- **Permanentï¼ˆæ°¸ä¹…æ€§ï¼‰**ï¼š401ã€422 â†’ é‡è¯•ä¸€ä¸‡æ¬¡ä¹Ÿæ²¡ç”¨ â†’ ç›´æ¥æŠ›å‡º

ç±»æ¯”ï¼šæ‰“ç”µè¯æ²¡æ¥ï¼ˆæš‚æ—¶çš„ï¼Œè¿‡ä¼šå„¿å†æ‰“ï¼‰ï¼Œå·ç æ˜¯ç©ºå·ï¼ˆæ°¸ä¹…çš„ï¼Œæ‰“å¤šå°‘æ¬¡éƒ½æ²¡ç”¨ï¼‰ã€‚

### æŒ‡æ•°é€€é¿ï¼ˆExponential Backoffï¼‰

é—®é¢˜ï¼šé‡è¯•ç­‰å¤šä¹…ï¼Ÿå›ºå®šç­‰ 1 ç§’ â†’ æ‰€æœ‰å®¢æˆ·ç«¯åŒæ—¶é‡è¯• â†’ é‡è¯•é£æš´ã€‚

è§£æ³•ï¼šæ¯æ¬¡é‡è¯•ï¼Œç­‰å¾…æ—¶é—´ç¿»å€ã€‚

å…¬å¼ï¼š`delay = min(base_delay Ã— 2^attempt, max_delay)`

- attempt 0 â†’ 1s
- attempt 1 â†’ 2s
- attempt 2 â†’ 4s
- attempt 3 â†’ 8s

max_delay æ˜¯å®‰å…¨é˜€ï¼Œé˜²æ­¢ç­‰å¾…æ—¶é—´æŒ‡æ•°çˆ†ç‚¸ã€‚

è¿›é˜¶ï¼šJitterï¼ˆéšæœºæŠ–åŠ¨ï¼‰åœ¨ç­‰å¾…æ—¶é—´ä¸ŠåŠ éšæœºåç§»ï¼Œè¿›ä¸€æ­¥æ‰“æ•£é‡è¯•æ—¶æœºã€‚

------

## Howï¼šæœ€å°å¯è¿è¡ŒèŒƒå¼

### æ ¸å¿ƒç»„ä»¶ï¼šRetryHandler

```python
class RetryHandler:
    def __init__(self, max_retries=3, base_delay=1, max_delay=10, retryable_errors=()):
        self.max_retries = max_retries
        self.base_delay = base_delay
        self.max_delay = max_delay
        self.retryable_errors = retryable_errors

    def is_retryable_error(self, error) -> bool:
        return isinstance(error, self.retryable_errors)

    def execute(self, operation, *args, **kwargs):
        retry_count = 0  # å±€éƒ¨å˜é‡ï¼Œä¸æ˜¯å®ä¾‹å±æ€§ï¼
        while True:
            try:
                return operation(*args, **kwargs)
            except Exception as e:
                if not self.is_retryable_error(e):
                    raise
                if retry_count >= self.max_retries:
                    raise
                retry_count += 1
                delay = min(self.base_delay * 2 ** (retry_count - 1), self.max_delay)
                time.sleep(delay)
```

### ç»„åˆè¿› LLMClient

```python
class LLMClient:
    def __init__(self, provider: LLMProvider, retry_handler: RetryHandler):
        self.provider = provider
        self.retry_handler = retry_handler

    def chat(self, request: ChatRequest) -> ChatResponse:
        return self.retry_handler.execute(self.provider.chat, request)
```

### å¼‚å¸¸ä½“ç³»

```python
class LLMError(Exception): pass          # åŸºç±»ï¼Œå¿…é¡»ç»§æ‰¿ Exception
class LLMTimeoutError(LLMError): pass    # å¯é‡è¯•
class LLMRateLimitError(LLMError): pass  # å¯é‡è¯•
class LLMServerError(LLMError): pass     # å¯é‡è¯•
class LLMAuthError(LLMError): pass       # ä¸å¯é‡è¯•
class LLMRequestError(LLMError): pass    # ä¸å¯é‡è¯•
```

### ç»„è£…

```python
retry_handler = RetryHandler(
    retryable_errors=(LLMTimeoutError, LLMRateLimitError, LLMServerError)
)
client = LLMClient(provider=provider, retry_handler=retry_handler)
```

------

## Pitfallï¼šçœŸå®è¸©å‘

- **retry_count æ”¾æˆå®ä¾‹å±æ€§**ï¼šç¬¬ä¸€æ¬¡è°ƒç”¨é‡è¯• 2 æ¬¡åï¼Œç¬¬äºŒæ¬¡è°ƒç”¨åªå‰© 1 æ¬¡é‡è¯•é¢åº¦ã€‚å¿…é¡»æ˜¯ execute() å†…çš„å±€éƒ¨å˜é‡ï¼Œæ¯æ¬¡è°ƒç”¨äº’ç›¸ç‹¬ç«‹
- **LLMError å¿˜è®°ç»§æ‰¿ Exception**ï¼šPython ä¸å…è®¸ raise ä¸€ä¸ªéå¼‚å¸¸å¯¹è±¡ï¼Œ`raise LLMTimeoutError()` ä¼šç›´æ¥æŠ¥ TypeError
- **retryable_errors é»˜è®¤ç©º tuple**ï¼šä¸ä¼  = ä»€ä¹ˆéƒ½ä¸é‡è¯•ã€‚`isinstance(error, ())` æ°¸è¿œ False
- **ChatResponse ç¼ºå­—æ®µ**ï¼šFailingMockProvider æˆåŠŸè¿”å›æ—¶å¿˜äº†ä¼  input_tokens/output_tokensï¼Œdataclass ä¼šæŠ¥ missing arguments

------

## Applicationï¼šåœ¨ RAG / Agent / æ¶æ„ä¸­çš„ä½ç½®

- **RAG**ï¼šæ£€ç´¢æ—¶è°ƒ Embedding API + ç”Ÿæˆæ—¶è°ƒ LLM APIï¼Œä»»ä½•ä¸€æ­¥éƒ½éœ€è¦é‡è¯•
- **Agent**ï¼šå·¥å…·è°ƒç”¨å¤±è´¥ã€LLM è§„åˆ’å¤±è´¥ï¼Œéƒ½èµ° RetryHandler çš„é‡è¯•é€»è¾‘
- **ç”Ÿäº§æœåŠ¡**ï¼šMonth 6 ä¼šåŠ æ›´å®Œæ•´çš„è§‚æµ‹ï¼ˆé‡è¯•æ¬¡æ•°æŒ‡æ ‡ã€å¤±è´¥ç‡å‘Šè­¦ï¼‰ï¼ŒRetryHandler æ˜¯è§‚æµ‹æ•°æ®çš„æ¥æº

------

## è§†è§‰é—­ç¯

```
chat(request)
    â”‚
    â–¼
RetryHandler.execute()
    â”‚
    â”œâ”€ try: provider.chat(request) â”€â”€â†’ æˆåŠŸ â†’ è¿”å› ChatResponse
    â”‚
    â””â”€ except:
        â”‚
        â”œâ”€ is_retryable? â”€â”€Noâ”€â”€â†’ ç›´æ¥ raiseï¼ˆ401/422ï¼‰
        â”‚
        â””â”€ Yes
            â”‚
            â”œâ”€ è¶…è¿‡ max_retries? â”€â”€Yesâ”€â”€â†’ raise
            â”‚
            â””â”€ No â†’ sleep(delay) â†’ å›åˆ° try
                     delay = min(base Ã— 2^attempt, max)

ç»„åˆå…³ç³»ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLMClient                      â”‚
â”‚  â”œâ”€â”€ provider: LLMProvider     â”‚  â† D1
â”‚  â””â”€â”€ retry_handler: RetryHandlerâ”‚ â† D2
â”‚       â”œâ”€â”€ retryable_errors     â”‚
â”‚       â””â”€â”€ execute() åŒ…è£¹è°ƒç”¨    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

------

## å·¥ç¨‹å¸ˆè®°å¿†åˆ†å±‚

- ğŸ—‘ï¸ åƒåœ¾åŒºï¼ˆæŸ¥æ–‡æ¡£ï¼‰ï¼štime.sleep() çš„ç²¾ç¡®ç”¨æ³•ã€isinstance æ”¯æŒ tuple çš„è¯­æ³•ç»†èŠ‚
- ğŸ” ç´¢å¼•åŒºï¼ˆè®°å…³é”®è¯ï¼‰ï¼šJitter éšæœºæŠ–åŠ¨ã€Retry Storm é‡è¯•é£æš´ã€min() å°é¡¶
- ğŸ’ æ ¸å¿ƒåŒºï¼ˆå¿…é¡»å†…åŒ–ï¼‰ï¼šTransient vs Permanent é”™è¯¯åˆ†ç±»å†³å®šé‡è¯•ç­–ç•¥ï¼›æŒ‡æ•°é€€é¿å…¬å¼ `min(base Ã— 2^attempt, max)`ï¼›RetryHandler ç‹¬ç«‹äº LLMClientï¼Œé€šè¿‡ç»„åˆæ³¨å…¥ï¼›retry_count å¿…é¡»æ˜¯å±€éƒ¨å˜é‡ä¸æ˜¯å®ä¾‹å±æ€§

---

# M2-W5-D3ï¼ˆç»“æ„åŒ–è¾“å‡ºï¼šJSON schemaçº¦æŸ+è§£æå®¹é”™ï¼‰

## A. å¤´éƒ¨

- **Phase**ï¼šMonth 2 - LLM API å·¥ç¨‹åŒ– / Week 5 - LLMClient åŸºç¡€å°è£…
- **ä»Šæ—¥æ ¸å¿ƒç›®æ ‡**ï¼šå½“ LLM è¾“å‡ºä¸æ˜¯çº¯ JSON æ—¶ï¼Œèƒ½ç¨³å®šæå–å¹¶è§£æï¼Œå¤±è´¥æ—¶ä¼˜é›…é™çº§

------

## B. æ­£æ–‡

### Whyï¼šä¸å­¦ä¼šå¯¼è‡´çš„å·¥ç¨‹æ­»ç©´

LLM æœ¬è´¨æ˜¯æ–‡å­—æ¥é¾™å¼•æ“ï¼Œä¸æ˜¯ JSON ç”Ÿæˆå™¨ã€‚å³ä½¿ prompt é‡Œå†™äº†"åªè¿”å› JSON"ï¼Œå®ƒä»å¯èƒ½ï¼š

- åœ¨ JSON å‰ååŠ è§£é‡Šæ–‡å­—
- ç”¨å•å¼•å·ä»£æ›¿åŒå¼•å·
- å­—æ®µåæ‹¼é”™ã€å¤šé€—å·

å¦‚æœä¸åšå®¹é”™ï¼Œ`json.loads()` ä¸€æŠ¥é”™ï¼Œæ•´ä¸ªè¯·æ±‚é“¾è·¯å°±å´©äº†ã€‚ç”Ÿäº§ç¯å¢ƒé‡Œè¿™ç§é—®é¢˜æ¯å¤©éƒ½ä¼šå‘ç”Ÿã€‚

------

### Whatï¼šç¬¬ä¸€æ€§åŸç† + ç±»æ¯”

ç»“æ„åŒ–è¾“å‡ºå¤±è´¥æœ‰ä¸‰ç§å½¢å¼ï¼š

- **åŒ…è£¹æ–‡æœ¬**ï¼šJSON è¢«è‡ªç„¶è¯­è¨€åŒ…è£¹ï¼ˆæœ€å¸¸è§ï¼‰
- **æ ¼å¼é”™è¯¯**ï¼šå•å¼•å·ã€å¤šä½™é€—å·ã€ç¼ºå­—æ®µ
- **å†…å®¹ç¼ºå¤±**ï¼šå­—æ®µä¸å…¨æˆ–ç±»å‹ä¸å¯¹

ç±»æ¯”ï¼šå°±åƒå¿«é€’å‘˜æŠŠåŒ…è£¹å¡åœ¨ä¸€ä¸ªå¤§çº¸ç®±é‡Œï¼Œå¤–é¢è¿˜ç¼ äº†èƒ¶å¸¦å’ŒåºŸçº¸ã€‚ä½ è¦å…ˆæ‹†åŒ…è£…ï¼ˆextractï¼‰ï¼Œå†æ£€æŸ¥è´§ç‰©æ˜¯å¦å®Œå¥½ï¼ˆparseï¼‰ï¼Œåäº†å°±è®°å½•é—®é¢˜ï¼ˆexceptï¼‰ï¼Œä¸èƒ½ç›´æ¥æ‰”æ‰æ•´ä¸ªå¿«é€’ã€‚

------

### Howï¼šæœ€å°å¯è¿è¡ŒèŒƒå¼

**ç¬¬ä¸€æ­¥ï¼šæå–â€”â€”ä»æ–‡æœ¬é‡Œæ‰¾ JSON**

```python
import re

def extract_json(text: str) -> str | None:
    match = re.search(r'\{.*?\}', text, re.DOTALL)
    return match.group() if match else None
```

å…³é”®ç‚¹ï¼š

- `.*?` éè´ªå©ªï¼šæ‰¾åˆ°ç¬¬ä¸€ä¸ªå®Œæ•´ `{...}` å°±åœï¼Œä¸ä¼šæŠŠä¸¤ä¸ª JSON ä¸­é—´çš„æ–‡å­—ä¹Ÿåè¿›å»
- `re.DOTALL`ï¼šè®© `.` èƒ½åŒ¹é…æ¢è¡Œç¬¦ï¼Œå¤„ç†å¤šè¡Œ JSON

**ç¬¬äºŒæ­¥ï¼šè§£æâ€”â€”æå–ååšå®¹é”™ parse**

```python
import json

def parse_json(text: str) -> dict | None:
    raw = extract_json(text)
    try:
        return json.loads(raw) if raw else None
    except json.JSONDecodeError:
        return None
```

**ç¬¬ä¸‰æ­¥ï¼šé›†æˆåˆ° LLMClient**

```python
content = parse_json(response.content) or response.content
# è§£ææˆåŠŸ â†’ è¿”å›å­—å…¸
# è§£æå¤±è´¥ï¼ˆNoneï¼‰â†’ or fallbackï¼Œè¿”å›åŸå§‹å­—ç¬¦ä¸²ï¼Œä¸ä¸¢æ•°æ®
```

------

### Pitfallï¼šçœŸå®è¸©å‘

- æ­£åˆ™é‡Œç”¨äº†ä¸­æ–‡å…¨è§’é—®å· `ï¼Ÿ` â†’ åŒ¹é…å¤±è´¥ï¼Œè¿”å› Noneï¼Œæ’æŸ¥åŠå¤©æ‰¾ä¸åˆ°åŸå› 
- `try/except` é‡Œå¿˜äº† `return` â†’ è§£ææˆåŠŸä¹Ÿè¿”å› Noneï¼Œæ•°æ®é»˜é»˜ä¸¢å¤±
- Mock æ•°æ®ç”¨å•å¼•å· `'a': 1` â†’ `json.loads` æŠ¥é”™ï¼Œè¯¯ä»¥ä¸º parse_json æœ‰ bugï¼Œå…¶å®æ˜¯æµ‹è¯•æ•°æ®ä¸åˆæ³•
- `.*` è´ªå©ªåŒ¹é… â†’ ä¸¤ä¸ª JSON ä¹‹é—´çš„æ–‡å­—è¢«åè¿›å»ï¼Œæ‹¿åˆ°ä¸€ä¸ªæ— æ³•è§£æçš„å¤§å­—ç¬¦ä¸²

------

### Applicationï¼šåœ¨ RAG/Agent/æ¶æ„ä¸­çš„ä½ç½®

```
ç”¨æˆ·è¯·æ±‚
    â†“
LLMClient.chat()
    â†“
Provider è¿”å›åŸå§‹æ–‡æœ¬
    â†“
parse_json()  â† ä»Šå¤©çš„ä½ç½®
    â†“
è¿”å›å­—å…¸ï¼ˆæˆåŠŸï¼‰æˆ–åŸå§‹å­—ç¬¦ä¸²ï¼ˆå¤±è´¥ï¼‰
    â†“
è°ƒç”¨æ–¹
```

åœ¨ RAG é‡Œï¼ŒLLM ç”Ÿæˆå¸¦å¼•ç”¨çš„ç»“æ„åŒ–ç­”æ¡ˆï¼ˆå¦‚ `{"answer": "...", "sources": [...]}`ï¼‰ï¼Œå¿…é¡»ç”¨ä»Šå¤©çš„æ–¹æ³•è§£æã€‚Agent é‡Œï¼ŒLLM å†³ç­–ä¸‹ä¸€æ­¥å·¥å…·è°ƒç”¨æ—¶è¿”å›çš„ä¹Ÿæ˜¯ JSONï¼Œè§£æå¤±è´¥ä¼šå¯¼è‡´æ•´ä¸ª Agent å¡æ­»ã€‚

------

## C. è§†è§‰é—­ç¯

```
LLM åŸå§‹è¾“å‡º
"å¥½çš„ï¼Œåˆ†æç»“æœï¼š{\"intent\": \"æŸ¥è¯¢\", \"city\": \"æ·±åœ³\"} å¸Œæœ›æœ‰å¸®åŠ©"
        â”‚
        â–¼
  extract_json()
  re.search(r'\{.*?\}')
        â”‚
        â”œâ”€ æ‰¾åˆ° â†’ "{\"intent\": \"æŸ¥è¯¢\", \"city\": \"æ·±åœ³\"}"
        â”‚
        â–¼
   parse_json()
   json.loads()
        â”‚
        â”œâ”€ æˆåŠŸ â†’ {"intent": "æŸ¥è¯¢", "city": "æ·±åœ³"}  âœ…
        â”‚
        â””â”€ å¤±è´¥ â†’ None â†’ or â†’ åŸå§‹å­—ç¬¦ä¸² fallback     âš ï¸
```

------

## D. å·¥ç¨‹å¸ˆè®°å¿†åˆ†å±‚

ğŸ—‘ï¸ **åƒåœ¾åŒºï¼ˆæŸ¥æ–‡æ¡£ï¼‰**

- `re.DOTALL` çš„å…·ä½“æ•°å€¼
- `json.JSONDecodeError` çš„å®Œæ•´ç»§æ‰¿é“¾
- `re.search` vs `re.match` vs `re.findall` çš„å…¨éƒ¨å·®å¼‚

ğŸ” **ç´¢å¼•åŒºï¼ˆè®°å…³é”®è¯ï¼‰**

- æå– JSON ç”¨æ­£åˆ™ `\{.*?\}`ï¼Œéè´ªå©ª
- è§£æå¤±è´¥ç”¨ `json.JSONDecodeError` æ•è·
- fallback ç”¨ `or` åŸå§‹å­—ç¬¦ä¸²

ğŸ’ **æ ¸å¿ƒåŒºï¼ˆå¿…é¡»å†…åŒ–ï¼‰**

- LLM ä¸ä¿è¯è¾“å‡ºçº¯ JSONï¼Œå®¹é”™æ˜¯å·¥ç¨‹å¿…é€‰é¡¹ï¼Œä¸æ˜¯å¯é€‰é¡¹
- ä¸‰ç§å¤±è´¥å½¢å¼ï¼šåŒ…è£¹æ–‡æœ¬ / æ ¼å¼é”™è¯¯ / å†…å®¹ç¼ºå¤±
- è§£æé€»è¾‘æ”¾åœ¨ LLMClient å†…éƒ¨ï¼Œè°ƒç”¨æ–¹ä¸åº”è¯¥å…³å¿ƒè¿™ä¸ªç»†èŠ‚ï¼ˆå°è£…åŸåˆ™ï¼‰
- å¤±è´¥æ—¶ä¸èƒ½ä¸¢æ•°æ®ï¼Œè¦ fallback åˆ°åŸå§‹å­—ç¬¦ä¸²

---

# M2-W5-D4 

**Phase**ï¼šMonth 2 Â· Week 5 Â· Day 4 â€” LLM API å·¥ç¨‹åŒ–
 **ä»Šæ—¥æ ¸å¿ƒç›®æ ‡**ï¼šå®ç° MockProviderï¼Œç”¨å•å…ƒæµ‹è¯•éªŒè¯ LLMClient çš„æ ¸å¿ƒè¡Œä¸º

------

## Whyï¼šä¸å­¦ä¼šå¯¼è‡´çš„å·¥ç¨‹æ­»ç©´

æ²¡æœ‰ Mockï¼Œæµ‹è¯•å°±å¿…é¡»çœŸå®è°ƒç”¨ APIï¼š

- **çƒ§é’±**ï¼šæ¯æ¬¡è·‘ CI/CD éƒ½åœ¨æ¶ˆè€— API é¢åº¦ï¼Œç§¯å°‘æˆå¤š
- **æ…¢**ï¼šå•æ¬¡ 1-3 ç§’ï¼Œ50 ä¸ªæµ‹è¯•å°±æ˜¯ 2 åˆ†é’Ÿï¼Œæ²¡äººæ„¿æ„é¢‘ç¹è·‘
- **ä¸ç¨³å®š**ï¼šæ¨¡å‹æ¯æ¬¡è¿”å›ä¸åŒï¼Œ`assert response == "xxx"` æ°¸è¿œæ— æ³•æˆç«‹

ç»“æœæ˜¯ï¼šè¦ä¹ˆä¸å†™æµ‹è¯•ï¼Œè¦ä¹ˆæµ‹è¯•å½¢åŒè™šè®¾ã€‚

------

## Whatï¼šç¬¬ä¸€æ€§åŸç† + ç±»æ¯”

**MockProvider æœ¬è´¨**ï¼šä¸€ä¸ªå®ç°äº† `Provider` æ¥å£çš„"æ¼”å‘˜"ã€‚

å®ƒé•¿å¾—å’ŒçœŸå® Provider ä¸€æ¨¡ä¸€æ ·ï¼ˆåŒæ ·çš„æ–¹æ³•ç­¾åï¼‰ï¼Œä½†å†…éƒ¨ä¸è°ƒç”¨ä»»ä½•ç½‘ç»œï¼Œåªæ˜¯ä»é¢„è®¾åˆ—è¡¨é‡ŒæŒ‰é¡ºåºå–å­—ç¬¦ä¸²è¿”å›ã€‚

ç±»æ¯”ï¼šè¯å‰§æ’ç»ƒæ—¶ç”¨é“å…·åˆ€ä»£æ›¿çœŸåˆ€â€”â€”å¯¼æ¼”ï¼ˆLLMClientï¼‰ä¸éœ€è¦çŸ¥é“æ˜¯çœŸçš„è¿˜æ˜¯å‡çš„ï¼Œæ’ç»ƒç…§æ ·è¿›è¡Œã€‚

**ä¸ºä»€ä¹ˆæ˜¯å®ç° Provider æ¥å£ï¼Œè€Œä¸æ˜¯ç»§æ‰¿ LLMClientï¼Ÿ**
 LLMClient æ˜¯"è°ƒç”¨æ–¹"ï¼ŒProvider æ˜¯"æ•°æ®æ¥æºæ–¹"ã€‚Mock çš„æ˜¯æ•°æ®æ¥æºï¼Œä¸æ˜¯è°ƒç”¨é€»è¾‘ã€‚è¿™æ­£æ˜¯ D1 å­¦çš„"ç»„åˆä¼˜äºç»§æ‰¿"çš„å®é™…åº”ç”¨ã€‚

------

## Howï¼šæœ€å°å¯è¿è¡ŒèŒƒå¼

### MockProvider

```python
class MockProvider:
    def __init__(self, responses: list[str]):
        self.responses = responses

    def chat(self, request: ChatRequest) -> ChatResponse:
        if not self.responses:
            raise ValueError("MockProvider çš„é¢„è®¾å›ç­”å·²ç”¨å®Œ")
        return ChatResponse(
            content=self.responses.pop(0),
            input_tokens=len(request.messages),
            output_tokens=10,
        )
```

### ä¸‰ç±»å•å…ƒæµ‹è¯•

```python
# åœºæ™¯1ï¼šæ­£å¸¸è¿”å›
def test_normal_response():
    mock = MockProvider(responses=["ä½ å¥½"])
    client = LLMClient(provider=mock, retry_handler=retry_handler)
    response = client.chat(ChatRequest(messages=[{"role": "user", "content": "Hi"}]))
    assert response.content == "ä½ å¥½"

# åœºæ™¯2ï¼šå¤šæ¬¡è°ƒç”¨é¡ºåºæ­£ç¡®
def test_multiple_responses():
    mock = MockProvider(responses=["ç¬¬ä¸€ä¸ª", "ç¬¬äºŒä¸ª"])
    client = LLMClient(provider=mock, retry_handler=retry_handler)
    assert client.chat(...).content == "ç¬¬ä¸€ä¸ª"
    assert client.chat(...).content == "ç¬¬äºŒä¸ª"

# åœºæ™¯3ï¼šé¢„è®¾ç”¨å®ŒæŠ›å¼‚å¸¸
def test_responses_exhausted():
    with pytest.raises(ValueError):
        mock = MockProvider(responses=["ä»…ä¸€ä¸ª"])
        client = LLMClient(provider=mock)
        client.chat(...)  # ç¬¬ä¸€æ¬¡æˆåŠŸ
        client.chat(...)  # ç¬¬äºŒæ¬¡è§¦å‘ ValueError
```

------

## Pitfallï¼šçœŸå®è¸©å‘

- `pytest.raises` çš„ `with` å—é‡Œï¼Œ**å¼‚å¸¸ä¹‹åçš„ä»£ç ä¸ä¼šæ‰§è¡Œ**ã€‚å†™åœ¨é‡Œé¢çš„ `assert` å¦‚æœæ”¾åœ¨è§¦å‘å¼‚å¸¸çš„ä»£ç åé¢ï¼Œæ°¸è¿œä¸ä¼šè·‘åˆ°ï¼Œå±äºæ— æ•ˆæ–­è¨€ï¼Œè¦åˆ æ‰ã€‚

- `src` å¸ƒå±€ä¸‹ pytest æ‰¾ä¸åˆ°æ¨¡å—ï¼Œéœ€è¦åœ¨ `pyproject.toml` é…ç½®ï¼š

  ```toml
  [tool.pytest.ini_options]
  pythonpath = ["src"]
  ```

  å¦åˆ™åªèƒ½æ¯æ¬¡æ‰‹åŠ¨åŠ  `PYTHONPATH=src` å‰ç¼€ï¼Œå®¹æ˜“å¿˜ã€‚

- `MockProvider` çš„ `responses` åˆ—è¡¨**ä¸è¦åœ¨æ–¹æ³•å‚æ•°é‡Œä¼ **ï¼Œè¦åœ¨ `__init__` é‡Œä¼ ã€‚æ–¹æ³•å‚æ•°åªæ¥å— `ChatRequest`ï¼Œå¦åˆ™ç ´å Protocol æ¥å£ä¸€è‡´æ€§ï¼Œæ³¨å…¥è¿› LLMClient ä¼šæŠ¥ç±»å‹é”™è¯¯ã€‚

------

## Applicationï¼šåœ¨ RAG/Agent/æ¶æ„ä¸­çš„ä½ç½®

```
æµ‹è¯•å±‚
  â””â”€â”€ test_llm_client.py
        â”œâ”€â”€ MockProviderï¼ˆå‡æ•°æ®æºï¼‰  â† ä»Šå¤©
        â””â”€â”€ LLMClientï¼ˆè¢«æµ‹å¯¹è±¡ï¼‰

ç”Ÿäº§å±‚
  â””â”€â”€ LLMClient
        â””â”€â”€ OpenAIProvider / DeepSeekProviderï¼ˆçœŸå®æ•°æ®æºï¼‰
```

MockProvider åœ¨ Month 3 RAGã€Month 5 Agent ä¸­åŒæ ·é€‚ç”¨ï¼šå‡¡æ˜¯ä¾èµ–å¤–éƒ¨æœåŠ¡çš„æ¨¡å—ï¼Œéƒ½å¯ä»¥ç”¨åŒæ ·çš„æ¨¡å¼æ³¨å…¥ Mockï¼Œè®©æ•´ä¸ªæµ‹è¯•ä½“ç³»è„±ç¦»ç½‘ç»œç‹¬ç«‹è¿è¡Œã€‚

------

## è§†è§‰é—­ç¯

```
æµ‹è¯•é˜¶æ®µ                    ç”Ÿäº§é˜¶æ®µ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LLMClient                   LLMClient
    â”‚                           â”‚
    â–¼                           â–¼
MockProvider               OpenAIProvider
  (å‡æ•°æ®ï¼Œå¯æ§)              (çœŸå®APIï¼Œä¸å¯æ§)
  pop(0) å–é¢„è®¾å€¼             HTTP è¯·æ±‚è¿”å›
    â”‚                           â”‚
    â–¼                           â–¼
ChatResponse               ChatResponse
  content="ä½ å¥½"             content="æ¨¡å‹çœŸå®å›å¤"

ä¸¤è€…å¯¹ LLMClient å®Œå…¨é€æ˜ â†’ ç»„åˆä¼˜äºç»§æ‰¿çš„ä»·å€¼
```

------

## å·¥ç¨‹å¸ˆè®°å¿†åˆ†å±‚

ğŸ—‘ï¸ åƒåœ¾åŒºï¼ˆæŸ¥æ–‡æ¡£ï¼‰

- `pytest.raises` çš„å…·ä½“è¯­æ³•
- `pyproject.toml` çš„é…ç½®å­—æ®µå
- `pop(0)` è¿˜æ˜¯ `pop(-1)`

ğŸ” ç´¢å¼•åŒºï¼ˆè®°å…³é”®è¯ï¼‰

- Mock = å®ç° Provider æ¥å£çš„å‡æ•°æ®æº
- src å¸ƒå±€ â†’ pythonpath é…ç½®
- pytest ä¸‰æ®µå¼ï¼šå‡†å¤‡ / æ‰§è¡Œ / æ–­è¨€

ğŸ’ æ ¸å¿ƒåŒºï¼ˆå¿…é¡»å†…åŒ–ï¼‰

- **ä¸ºä»€ä¹ˆéœ€è¦ Mock**ï¼šçœé’± + å¤Ÿå¿« + ç¡®å®šæ€§ï¼Œç¼ºä¸€ä¸å¯
- **Mock åœ¨å“ªä¸€å±‚**ï¼šæ›¿æ¢ Providerï¼Œä¸æ›¿æ¢ LLMClientï¼Œä½“ç°"ç»„åˆä¼˜äºç»§æ‰¿"
- **pytest.raises çš„è¯­ä¹‰**ï¼šä¸æ˜¯"æ•è·å¼‚å¸¸"ï¼Œæ˜¯"æ–­è¨€å¿…é¡»æŠ›å¼‚å¸¸ï¼Œå¦åˆ™æµ‹è¯•å¤±è´¥"

---

