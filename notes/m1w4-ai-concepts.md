# 【全栈宗师笔记】M1-W4-WE2：AI 工程概念扫盲

> **Phase**: Month 1 · Week 4 · Weekend 2（必做）
> **今日核心目标**: 理解 8 个 AI 工程核心概念，为 M2 LLM API 工程化打下认知地基

---

## Why — 不学会导致的工程死穴

Month 2 开始你要亲手封装 LLMClient、写 Provider 抽象、处理结构化输出。如果这 8 个概念是模糊的：
- 不懂 Token → 写不出成本统计，上线后账单爆炸都不知道为什么
- 不懂上下文窗口 → 请求莫名报错，debug 半天找不到原因
- 不懂温度 → 该确定的时候瞎编，该创意的时候死板
- 不懂结构化输出失败 → 线上 JSON 解析崩溃，服务挂掉
- 不懂 Embedding/向量 → Month 3 RAG 完全听不懂
- 不懂 RAG vs 微调 → 技术选型时选错方案，浪费几周
- 不懂幻觉 → 做的系统给用户瞎编，出事故
- 不懂评测 → "感觉效果挺好"，面试官一听就知道你没做过

---

## What — 8 个概念的第一性原理

### 概念 1：Token

**本质**：大模型不认字，只认数字。文本必须先切成小块（token），每块对应一个数字编号。

**关键认知**：
- Token ≠ 字 ≠ 词，切法由分词器（tokenizer）决定
- 不同模型的分词器不同，同一段文本 token 数可能不同
- 粗略估算：英文 1 词 ≈ 1.3 token，中文 1 字 ≈ 1.5–2 token
- **API 按 token 计费**（input token + output token，分别有单价）

### 概念 2：上下文窗口（Context Window）

**本质**：一次请求能塞入的 token 总量上限。超了直接报错（不会悄悄截断）。

**关键认知**：
- GPT-4o: 128K，Claude Sonnet: 200K，DeepSeek: 64K–128K
- 报错比截断好 → 截断了你不知道丢了什么，报错至少能及时发现
- 当知识量超过窗口 → 不能全塞，需要 RAG（先检索再塞入）

### 概念 3：温度（Temperature）

**本质**：控制输出的随机性。模型每步预测多个候选 token，温度决定是选最高分的还是随机抽。

**关键认知**：
- 低温（0.0–0.3）：确定、可预测、严谨 → 客服/代码/提取
- 高温（0.7–1.0）：随机、多样、有创意 → 写作/头脑风暴
- LLMClient 默认值建议 0.3（工程场景居多）

### 概念 4：结构化输出与失败模式

**本质**：大模型在"生成文本"，不是在"返回数据"。要求它输出 JSON，它可能搞砸。

**三种失败模式**：
- A. 多余文本包裹："好的，以下是结果：{...}" → 最高频
- B. JSON 语法错误：少引号、多逗号 → 中频
- C. 字段名漂移：返回 `emotion` 而不是 `sentiment` → 低频但最阴险

**容错三步**：提取（找 `{...}`）→ 修复（常见语法问题）→ 校验（必需字段检查）

**铁律**：永远假设它会炸，设计好炸了怎么办。

### 概念 5：Embedding（向量嵌入）

**本质**：把文本变成一组数字（向量），让语义相近的文本数字也相近。

**类比**：Embedding 模型 = 翻译器，把人话翻译成计算机能比大小的数字。

**关键认知**：
- 解决关键词匹配的致命缺陷（"坏了能换吗" vs "三年质保" 无共同词但语义相关）
- Embedding 模型 ≠ 聊天模型：输入文本 → 输出数字向量（非文字）
- 调 API 即可，不需要自己训练

### 概念 6：向量相似度

**本质**：比较两个向量有多接近，用余弦相似度衡量。

**关键认知**：
- 余弦相似度：1.0 = 最接近，0.0 = 无关
- 逐一比较 100 万向量太慢 → 向量数据库用近似最近邻（ANN）索引加速
- 近似 = 可能漏掉最佳结果，但快几千倍，工程上值得

### 概念 7：RAG vs 微调

**本质**：两种让模型"学会"新知识的方式，适用场景完全不同。

| | RAG | 微调 |
|---|---|---|
| 做法 | 先检索相关文档，塞进 prompt | 拿数据重新训练模型 |
| 更新 | 替换文档，几分钟 | 重新训练，几小时~几天 |
| 可追溯 | 能返回引用来源 | 说不清来源 |
| 成本 | 向量数据库 | GPU 训练费用 |

**一句话**：知识会变 → RAG，行为要变 → 微调

### 概念 8：幻觉与引用 + 评测

**幻觉**：模型一本正经编造不存在的内容（因为它靠概率生成，不是靠事实）。

**防线**：
- 温度调低 → 有帮助但不能消除
- RAG + 引用 → **最有效**（给原文 + 要求标注出处 → 编了也能查出来）

**评测铁律**：用数据说话，不靠感觉。
- ❌ "感觉效果不错"
- ✅ "20 条测试集，准确率 85%，比上版提升 5%"

---

## How — 概念串联链路

```
Token（计费单位）
  → 上下文窗口（token 上限，超了报错）
    → 温度（控制输出随机性）
      → 结构化输出（模型输出不可靠，必须容错）
        → Embedding（文本 → 向量）
          → 向量相似度（找最相关内容）
            → RAG vs 微调（知识变 → RAG，行为变 → 微调）
              → 幻觉与引用（RAG + 引用 = 最有效防线）
                → 评测（数据驱动，不靠感觉）
```

---

## Pitfall — 真实踩坑

| 坑 | 后果 | 正确做法 |
|---|---|---|
| 每次请求塞整本手册 | 月成本 2000+，还可能超窗口 | 用 RAG 只塞相关段落 |
| `json.loads(response)` 裸调 | 线上 5-10% 请求崩溃 | 提取→修复→校验三步容错 |
| 温度方向记反 | 该严谨时瞎编，该创意时死板 | 低温=严谨，高温=创意 |
| 用 LIKE 做语义搜索 | "坏了能换" 查不到 "质保服务" | 用 Embedding + 向量相似度 |
| 不做评测就上线 | 出问题说不清哪里错，改了不知道有没有变好 | 先建数据集和指标，再改进 |

---

## Application — 在 M2-M4 中的位置

| 概念 | 直接用于 |
|---|---|
| Token + 上下文窗口 | M2-W5：LLMClient 封装（成本统计 + 超限检查） |
| 温度 | M2-W5：LLMClient 参数设计 |
| 结构化输出 | M2-W5-D3：JSON 解析容错 |
| Embedding + 向量相似度 | M3-W9~W12：RAG 数据工程 |
| RAG vs 微调 | M3~M4：技术选型决策 |
| 幻觉与引用 | M3-W12-WE1 + M4-W15：引用格式 + Badcase 排查 |
| 评测 | M4-W14~W16：评测数据集 + 指标 + 回归门禁 |

---

## 视觉闭环：从文本到回答的完整数据流

```
用户提问
    │
    ▼
┌─────────────┐
│  Embedding   │ ← 把问题变成向量
│   模型       │
└──────┬──────┘
       │ 查询向量
       ▼
┌─────────────┐     ┌─────────────┐
│  向量数据库  │ ←── │ 文档向量库   │ ← 建库时：文档切块 → Embedding → 存入
│  相似度检索  │     │（100万段）   │
└──────┬──────┘     └─────────────┘
       │ Top K 相关段落
       ▼
┌─────────────┐
│ Prompt 组装  │ ← system prompt + 相关段落 + 用户问题
│ （≤ 窗口上限）│   （检查 token 数不超限）
└──────┬──────┘
       │
       ▼
┌─────────────┐
│  聊天模型    │ ← temperature 控制随机性
│ GPT/Claude  │
└──────┬──────┘
       │ 生成回答（可能含幻觉）
       ▼
┌─────────────┐
│ 输出处理     │ ← 结构化解析（提取→修复→校验）
│ + 引用标注   │   引用来源（用于追溯和排查）
└──────┬──────┘
       │
       ▼
  返回给用户
       │
       ▼
┌─────────────┐
│  评测体系    │ ← 数据集 + 指标 + 回归门禁
│ 持续监控改进  │
└─────────────┘
```

---

## 🧠 工程师记忆分层

### 🗑️ 垃圾区（查文档就行）
- tiktoken 具体用法
- 各模型的精确上下文窗口大小
- 余弦相似度的数学公式
- ANN 索引算法细节（HNSW/IVF）

### 🔍 索引区（记住关键词，用时能查到）
- 分词器（tokenizer）：不同模型切法不同
- 向量数据库选型：Chroma / FAISS / Milvus
- Embedding 模型选型：OpenAI / BGE / 本地
- LLM-as-Judge：用模型评测模型

### 💎 核心区（必须内化，面试脱口而出）
- Token 是计费单位，中文 1 字 ≈ 1.5–2 token
- 超窗口直接报错，不会截断
- 低温严谨，高温创意（别记反！）
- 结构化输出三种失败 + 容错三步：提取→修复→校验
- Embedding = 文本→向量，让语义可比较
- **知识变→RAG，行为变→微调**
- **RAG + 引用 = 幻觉最有效防线**
- **评测 = 用数据说话，不靠感觉**
- LLMClient 必须内建：token 统计、窗口检查、温度参数、输出容错

---

